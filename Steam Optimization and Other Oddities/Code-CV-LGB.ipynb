{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "374e57ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import KFold, GroupKFold\n",
    "import lightgbm as lgb\n",
    "from datetime import datetime, timedelta\n",
    "import gc\n",
    "import optuna\n",
    "from utils_testing import optuna_logging\n",
    "from itertools import combinations\n",
    "from termcolor import colored\n",
    "import pytz\n",
    "UTC = pytz.utc  \n",
    "\n",
    "timeZ_Kl = pytz.timezone('Asia/Kolkata')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ef38fbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_pickle(\"../data/train_df_interim.pickle\")\n",
    "test_df = pd.read_pickle(\"../data/test_df_interim.pickle\")\n",
    "\n",
    "train_df.shape, test_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac511885",
   "metadata": {},
   "outputs": [],
   "source": [
    "drop = ['SURV_DTE'\n",
    "        , 'sand_target_avg'\n",
    "        , 'fold'\n",
    "        \n",
    "       ]\n",
    "target = 'PCT_DESAT_TO_ORIG'\n",
    "indep = train_df.columns.difference(drop+[target])\n",
    "indep_master = indep.copy() # Taking a copy so it can be used to get the original features\n",
    "indep"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "059ed392",
   "metadata": {},
   "source": [
    "# LGBM"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b6b0f5c",
   "metadata": {},
   "source": [
    "### 5 fold Groupd CV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc159cbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def lgb_eval_rmse(preds, y_true):\n",
    "#     actual=y_true.get_label()\n",
    "    \n",
    "#     preds = np.where(preds>=1,1, preds)\n",
    "#     preds = np.where(preds<=0,0, preds)\n",
    "    \n",
    "#     fold_rmse = np.sqrt(mean_squared_error(actual, preds))\n",
    "    \n",
    "#     return \"lgb_rmse\", fold_rmse, False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ae85ffd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_lgb_model(train_df, lgb_params):\n",
    "    \n",
    "    num_rounds = 100000\n",
    "    \n",
    "    fold_iterations = []\n",
    "    fold_results = []\n",
    "    lgb_models_fold = {}\n",
    "\n",
    "    print(\"\")\n",
    "    for fold_i in range(0, train_df.fold.max()+1):\n",
    "\n",
    "        train_fold = train_df[train_df.fold!=fold_i].copy()\n",
    "        valid_fold = train_df[train_df.fold==fold_i].copy()\n",
    "    \n",
    "        lgb_train_local = lgb.Dataset(train_fold[indep], train_fold[target], free_raw_data=False)\n",
    "        lgb_test_local = lgb.Dataset(valid_fold[indep], valid_fold[target],\n",
    "                                     reference=lgb_train_local,  free_raw_data=False)                             \n",
    "\n",
    "        np.random.seed(100)\n",
    "        lgb_model_local = lgb.train(lgb_params,\n",
    "                                    lgb_train_local,\n",
    "                                    num_boost_round=num_rounds ,\n",
    "                                    valid_sets=lgb_test_local,\n",
    "        #                             feval=lgb_eval_rmspe,\n",
    "        #                             categorical_feature=['stock_id'],\n",
    "                                    early_stopping_rounds=50,\n",
    "                                    verbose_eval=False\n",
    "        #                             , callbacks=[lgb.reset_parameter(learning_rate = learning_rate_010_decay_power_0995)]\n",
    "                                   )\n",
    "        lgb_local_prediction = lgb_model_local.predict(valid_fold[indep])\n",
    "\n",
    "        lgb_local_prediction = np.where(lgb_local_prediction<0, 0, lgb_local_prediction)\n",
    "        lgb_local_prediction = np.where(lgb_local_prediction>1, 1, lgb_local_prediction)\n",
    "\n",
    "        fold_rmse = np.sqrt(mean_squared_error(valid_fold[target], lgb_local_prediction))\n",
    "        fold_iteration = lgb_model_local.best_iteration\n",
    "        \n",
    "        fold_iterations.append(fold_iteration)\n",
    "        fold_results.append(np.round(fold_rmse, 5))\n",
    "        lgb_models_fold[fold_i] = lgb_model_local\n",
    "        \n",
    "        print(f\"Current fold: {fold_i}, iteration {fold_iteration}, RMSE {fold_rmse}\")\n",
    "    \n",
    "    return fold_iterations, fold_results, lgb_models_fold"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c7591ad",
   "metadata": {},
   "source": [
    "### LGB optuna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40c853cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_lgb_model_optuna(trial):\n",
    "    \"\"\"\n",
    "    This function is used to train the model using the parameters obtained from optuna.\n",
    "    \"\"\"\n",
    "    lgbm_param = {\n",
    "                'objective': 'regression',\n",
    "                'metric': 'rmse',\n",
    "                'verbose': -1,\n",
    "                \"boosting_type\": \"gbdt\",\n",
    "#                 \"lambda_l1\": trial.suggest_float(\"lambda_l1\", 1e-1, 10.0, log=True),\n",
    "#                 \"lambda_l2\": trial.suggest_float(\"lambda_l2\", 1e-1, 10.0, log=True),\n",
    "                'learning_rate': trial.suggest_float(\"learning_rate\", 0.01, 0.3, log=True),\n",
    "                \"num_leaves\": trial.suggest_int(\"num_leaves\", 2**2, 2**6),\n",
    "                \"max_depth\": trial.suggest_int(\"max_depth\", 2, 8),\n",
    "                'feature_fraction': trial.suggest_float(\"feature_fraction\", 0.6, 1.0),\n",
    "                \"bagging_fraction\": trial.suggest_float(\"bagging_fraction\", 0.6, 1.0),\n",
    "#                 \"bagging_freq\": trial.suggest_int(\"bagging_freq\", 1, 3),\n",
    "                \"min_child_samples\": trial.suggest_int(\"min_child_samples\", 2, 25),\n",
    "            }\n",
    "\n",
    "    lgb_fold_iterations, lgb_fold_results, lgb_models_fold = train_lgb_model(train_df=train_df, \n",
    "                                                                             lgb_params = lgbm_param)\n",
    "    \n",
    "    avg_error = np.mean(lgb_fold_results)\n",
    "    print(\"Avg.Fold results:\", avg_error)\n",
    "\n",
    "    return avg_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b804be7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Optuna Hyper-parameter tuning\n",
    "lgb_study = optuna.create_study(direction=\"minimize\")\n",
    "lgb_study.optimize(train_lgb_model_optuna\n",
    "                   , n_trials=1000\n",
    "                   , n_jobs=1\n",
    "                   #                , timeout=600\n",
    "                   , show_progress_bar=True\n",
    "                   , gc_after_trial=True\n",
    "              )\n",
    "\n",
    "# Write the best hyer-parameter and the best RMSE to the logging file\n",
    "optuna_logging(model='lgb', study=lgb_study, indep=np.array(indep))\n",
    "\n",
    "print(\"Number of finished trials: \", len(lgb_study.trials))\n",
    "print(\"Best trial:\", lgb_study.best_trial.number)\n",
    "print(\"Best Value: {}\".format(lgb_study.best_trial.value))\n",
    "print(\"Params: \")\n",
    "lgb_study.best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83881726",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read all the hyperparameters and their best RMSE from the logged file\n",
    "filename = f\"../Optuna_logging/lgb_optuna_logging.csv\"\n",
    "temp = pd.read_csv(filename)\n",
    "temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "844a89d9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "best_RMSE = temp.best_RMSE.min()\n",
    "lgb_params = eval(temp.best_param[temp.best_RMSE==best_RMSE].values[0])\n",
    "print(f\"The parameter corresponding to the best RMSE {best_RMSE}\")\n",
    "lgb_params"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ec8f95b",
   "metadata": {},
   "source": [
    "# Indep combination"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e272f9f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_indep_combination(indep_all_combo, total_combinations_to_try):\n",
    "    \"\"\"\n",
    "    This function trains the LGB model based on the different combinations of independent \n",
    "    features from the overall features that is available and write it to the file \n",
    "    lgb_best_indep_combo.csv\n",
    "    \"\"\"\n",
    "    \n",
    "    lgb_params = {\n",
    "    #     'device_type':'gpu',\n",
    "    #     'nthreads':12,\n",
    "        'boosting_type': 'gbdt',\n",
    "        'objective': 'regression',\n",
    "    #     'num_class':4,\n",
    "#         'metric': 'custom',\n",
    "        'metric': 'rmse',\n",
    "        'num_leaves': 2**3,\n",
    "    #     'max_depth': 7,\n",
    "        'learning_rate': 0.04,\n",
    "        'feature_fraction': 1,\n",
    "        'bagging_fraction': 0.9,\n",
    "        'bagging_freq': 1,\n",
    "        'min_child_samples':20,\n",
    "        'verbose': -1\n",
    "    }\n",
    "\n",
    "\n",
    "    # reading the iterations ran so far\n",
    "    global overall_best\n",
    "    overall_best = pd.read_csv(\"../indep_combo/lgb_best_indep_combo.csv\")\n",
    "#     overall_best['indep'] = overall_best.indep.apply(lambda x : eval(x))\n",
    "\n",
    "    random_index = np.random.choice(len(indep_all_combo), \n",
    "                                    total_combinations_to_try, \n",
    "                                    replace=False)\n",
    "    mean_fold_result = []\n",
    "    best_result={}\n",
    "    indep_df = []\n",
    "\n",
    "    # declare the indep as global so the changes can be reflected in the training function\n",
    "    global indep \n",
    "    \n",
    "    best = 10000\n",
    "    for i, indep_ind in enumerate(random_index):\n",
    "        indep= indep_all_combo[indep_ind]\n",
    "        print(f\"{i}/{total_combinations_to_try}\")\n",
    "\n",
    "        fold_iterations, fold_results, lgb_models_fold = train_lgb_model(train_df=train_df,\n",
    "                                                                         lgb_params = lgb_params)\n",
    "        mean_fold_result.append(np.mean(fold_results))\n",
    "        indep_df.append(indep)\n",
    "        avg_iteration = int(np.mean(fold_iterations))\n",
    "\n",
    "        print(\"Fold iterations:\", fold_iterations)\n",
    "        print(\"Average iteration:\", avg_iteration)\n",
    "        print(\"Fold results:\", fold_results)\n",
    "        print(\"Avg.Fold results:\", mean_fold_result[-1])\n",
    "\n",
    "        # Printing the current best\n",
    "        if mean_fold_result[-1]<best:\n",
    "            best = mean_fold_result[-1]\n",
    "            print(colored(f\"New best {best}\", 'green'))\n",
    "            \n",
    "            # Reading and writing the indep combo\n",
    "            overall_best = pd.read_csv(\"../indep_combo/lgb_best_indep_combo.csv\")\n",
    "            best_indep = pd.DataFrame({'Date':datetime.now(timeZ_Kl).strftime('%d-%m-%Y %H:%M:%S'),\n",
    "                                       'indep': str(indep), \n",
    "                                       'rmse': [best]})\n",
    "            \n",
    "            print(colored(\"writing the indep combos to disk\", 'blue'))\n",
    "            overall_best = overall_best.append(best_indep).drop_duplicates().reset_index(drop=True)\n",
    "            overall_best.to_csv(\"../indep_combo/lgb_best_indep_combo.csv\", index=False)\n",
    "            \n",
    "        else:\n",
    "            print(colored(f\"Best so far {best}\", 'yellow'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df25e18a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Total actual features: {len(indep_master)}\")\n",
    "\n",
    "features_2_use=31\n",
    "comb_features = combinations(indep_master, features_2_use)\n",
    "\n",
    "indep_all_combo=[]\n",
    "for indep_combo in list(comb_features):\n",
    "    indep_all_combo.append(list(indep_combo))\n",
    "    \n",
    "print(f\"Total features to use: {features_2_use}\")\n",
    "print(f\"Total combo possible : {len(indep_all_combo)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ba3f6da",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "get_indep_combination(indep_all_combo=indep_all_combo, \n",
    "                      total_combinations_to_try=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e553db11",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Extract the parameters and the independent features with the best metric\n",
    "\n",
    "days_before = 0\n",
    "\n",
    "best_indep = pd.read_csv(\"../indep_combo/lgb_best_indep_combo.csv\")\n",
    "best_indep['Date'] = pd.to_datetime(best_indep.Date).dt.date.astype('str')\n",
    "\n",
    "today_date = (datetime.now()-timedelta(days=days_before)).strftime('%Y-%m-%d')\n",
    "print(today_date)\n",
    "\n",
    "condition1 = (best_indep.Date==today_date)\n",
    "best_indep = best_indep[condition1].reset_index(drop=True)\n",
    "\n",
    "condition2 = (best_indep.rmse == best_indep.rmse.min())\n",
    "indep = eval(best_indep[condition2].indep.values[0])\n",
    "lgb_params = eval(best_indep[condition2].params.values[0])\n",
    "\n",
    "print(f\"Best RMSE : {best_indep.rmse.min()}\")\n",
    "print(\"Best indep size\", len(indep))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "011a9b3b",
   "metadata": {},
   "source": [
    "### local"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "865b9435",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "lgb_params = {'boosting_type': 'gbdt',\n",
    "              'objective': 'regression',\n",
    "              'metric': 'rmse',\n",
    "              'num_leaves': 8,\n",
    "              'learning_rate': 0.04,\n",
    "              'feature_fraction': 1,\n",
    "              'bagging_fraction': 0.9,\n",
    "              'bagging_freq': 1,\n",
    "              'min_child_samples': 20,\n",
    "              'verbose': -1}\n",
    "\n",
    "\n",
    "lgb_params['boosting_type'] = 'gbdt'\n",
    "lgb_params['objective'] = 'regression'\n",
    "lgb_params['metric'] = 'rmse'\n",
    "lgb_params['verbose'] = -1\n",
    "\n",
    "fold_iterations, fold_results, lgb_models_fold = train_lgb_model(train_df=train_df,\n",
    "                                                                 lgb_params = lgb_params)\n",
    "\n",
    "avg_iteration = int(np.mean(fold_iterations))\n",
    "print(\"Fold iterations:\", fold_iterations)\n",
    "print(\"Average iteration:\", avg_iteration)\n",
    "print(\"Fold results:\", fold_results)\n",
    "print(\"Avg.Fold results:\", np.mean(fold_results))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec85a7d9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "ind = 3\n",
    "lgb_imp = pd.DataFrame({'feature' : indep, \n",
    "                        'fea_imp' : lgb_models_fold[ind].feature_importance()}).sort_values(['fea_imp'], ascending=False).reset_index(drop=True)\n",
    "lgb_imp"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57fbb594",
   "metadata": {},
   "source": [
    "# Fold Ensemble predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c1162d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fold_ensemble(model_list, test):\n",
    "    \"\"\"\n",
    "    This is the Ensemble prediction of the final test data from the fold models\n",
    "    \"\"\"\n",
    "    \n",
    "    ens_pred = []\n",
    "    for i in model_list.keys():\n",
    "        print(f\"Prediction for model {i}\")  \n",
    "        \n",
    "        fold_pred = model_list[i].predict(test[indep])\n",
    "        fold_pred = np.where(fold_pred<0, 0, fold_pred)\n",
    "        fold_pred = np.where(fold_pred>1, 1, fold_pred)\n",
    "        ens_pred.append(fold_pred)\n",
    "        \n",
    "    ensemble_prediction = np.array(ens_pred).mean(axis=0)\n",
    "           \n",
    "    return ensemble_prediction\n",
    "        \n",
    "# lgb_prod_prediction = fold_ensemble(model_list=lgb_models_fold, test=test_df)\n",
    "# lgb_prod_prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31602b78",
   "metadata": {},
   "source": [
    "### Prod"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b80b1969",
   "metadata": {},
   "outputs": [],
   "source": [
    "lgb_train_prod = lgb.Dataset(train_df[indep], train_df[target], free_raw_data=False)\n",
    "\n",
    "# params = trial.params\n",
    "# params['metric'] = 'rmse'\n",
    "# params['verbose'] = 1\n",
    "\n",
    "lgb_best_iteration = avg_iteration#+int(0.1*avg_iteration)\n",
    "print(f\"Training for {lgb_best_iteration}\")\n",
    "np.random.seed(100)\n",
    "lgb_model_prod = lgb.train(lgb_params\n",
    "                           ,lgb_train_prod\n",
    "                           ,num_boost_round=lgb_best_iteration\n",
    "#                            ,valid_sets=lgb_test_local\n",
    "#                            ,feval=lgb_eval_rmspe\n",
    "#                            ,categorical_feature=['stock_id']\n",
    "#                            ,early_stopping_rounds=50\n",
    "                          )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19f8b5ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "lgb_prod_prediction = lgb_model_prod.predict(test_df[indep])\n",
    "\n",
    "lgb_prod_prediction = np.where(lgb_prod_prediction<0, 0, lgb_prod_prediction)\n",
    "lgb_prod_prediction = np.where(lgb_prod_prediction>1, 1, lgb_prod_prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "101b5fbf",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "LGB_submission = pd.DataFrame({'PCT_DESAT_TO_ORIG':lgb_prod_prediction})\n",
    "LGB_submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b85aa64e",
   "metadata": {},
   "outputs": [],
   "source": [
    "LGB_submission.to_csv(\"../sub/LGB_sub_20.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9688d408",
   "metadata": {},
   "source": [
    "# Model Explainability using SHAP values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06140b97",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import shap\n",
    "shap.initjs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb7dca3c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "explainer = shap.TreeExplainer(lgb_models_fold[0])\n",
    "shap_values = explainer.shap_values(train_df.loc[train_df.fold!=1, indep].reset_index(drop=True))\n",
    "\n",
    "i =10\n",
    "shap.force_plot(explainer.expected_value, \n",
    "                shap_values[i], \n",
    "                features=train_df.loc[i, indep], \n",
    "                feature_names=train_df[indep].columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e4b8fbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "shap.summary_plot(shap_values, \n",
    "                  features=train_df[indep].reset_index(drop=True),\n",
    "                  feature_names=train_df[indep].columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81d83626",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
