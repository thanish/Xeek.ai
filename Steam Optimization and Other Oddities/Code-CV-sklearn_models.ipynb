{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "374e57ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor, ExtraTreesRegressor, AdaBoostRegressor\n",
    "from sklearn.model_selection import KFold, GroupKFold\n",
    "import xgboost as xgb\n",
    "from sklearn.svm import SVR\n",
    "\n",
    "from datetime import datetime\n",
    "import gc\n",
    "import optuna\n",
    "from utils import optuna_logging\n",
    "import pytz\n",
    "UTC = pytz.utc  \n",
    "timeZ_Kl = pytz.timezone('Asia/Kolkata')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ef38fbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_pickle(\"../data/train_df_interim.pickle\")\n",
    "test_df = pd.read_pickle(\"../data/test_df_interim.pickle\")\n",
    "\n",
    "train_df.shape, test_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53ad3d4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "drop = ['SURV_DTE'\n",
    "        , 'sand_target_avg'\n",
    "        , 'CMPL_FAC_ID'\n",
    "        , 'fold'\n",
    "        \n",
    "#         , 'SAND_AGE'\n",
    "#         , 'WELL_AGE'\n",
    "#         , 'WELL_SAND_AGE'\n",
    "#         , 'Well_last_active'\n",
    "#         , 'SAND_last_active'\n",
    "#         , 'Well_Sand_last_active'\n",
    "        \n",
    "#         ,'total_injected'\n",
    "       ]\n",
    "target = 'PCT_DESAT_TO_ORIG'\n",
    "indep = train_df.columns.difference(drop+[target])\n",
    "indep"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "426a43b6",
   "metadata": {},
   "source": [
    "# Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c908427",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_lm_model(train_df):\n",
    "    \n",
    "    num_rounds = 100000\n",
    "\n",
    "    fold_results = []\n",
    "    lm_models_fold = {}\n",
    "\n",
    "    print(\"\")\n",
    "    for fold_i in range(0, train_df.fold.max()+1):\n",
    "\n",
    "        train_fold = train_df[train_df.fold!=fold_i].copy()\n",
    "        valid_fold = train_df[train_df.fold==fold_i].copy()\n",
    "\n",
    "        np.random.seed(100)\n",
    "        lm_model_local = LinearRegression()\n",
    "        lm_model_local.fit(train_fold[indep], train_fold[target])\n",
    "        lm_local_prediction = lm_model_local.predict(valid_fold[indep])\n",
    "\n",
    "        lm_local_prediction = np.where(lm_local_prediction<0, 0, lm_local_prediction)\n",
    "        lm_local_prediction = np.where(lm_local_prediction>1, 1, lm_local_prediction)\n",
    "\n",
    "        fold_rmse = np.sqrt(mean_squared_error(valid_fold[target], lm_local_prediction))\n",
    "        \n",
    "        fold_results.append(np.round(fold_rmse, 5))\n",
    "        lm_models_fold[fold_i] = lm_model_local\n",
    "        \n",
    "        print(f\"Current fold: {fold_i}, RMSE {fold_rmse}\")\n",
    "    \n",
    "    return fold_results, lm_models_fold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aea1c4cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "lin_train_df = train_df.copy()\n",
    "lin_train_df = lin_train_df.replace({-999:0})\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "scaler.fit(lin_train_df[indep])\n",
    "lin_train_df[indep] = scaler.transform(lin_train_df[indep])\n",
    "\n",
    "fold_results, lgb_models_fold = train_lm_model(train_df=lin_train_df)\n",
    "\n",
    "print(\"Fold results:\", fold_results)\n",
    "print(\"Avg.Fold results:\", np.mean(fold_results))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e66ede55",
   "metadata": {},
   "source": [
    "# SVR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8100ade2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_svr_model(train_df):\n",
    "    \n",
    "    num_rounds = 100000\n",
    "\n",
    "    fold_results = []\n",
    "    svr_models_fold = {}\n",
    "\n",
    "    print(\"\")\n",
    "    for fold_i in range(0, train_df.fold.max()+1):\n",
    "\n",
    "        train_fold = train_df[train_df.fold!=fold_i].copy()\n",
    "        valid_fold = train_df[train_df.fold==fold_i].copy()\n",
    "\n",
    "        np.random.seed(100)\n",
    "        svr_model_local = SVR()\n",
    "        svr_model_local.fit(train_fold[indep], train_fold[target])\n",
    "        svr_local_prediction = svr_model_local.predict(valid_fold[indep])\n",
    "\n",
    "        svr_local_prediction = np.where(svr_local_prediction<0, 0, svr_local_prediction)\n",
    "        svr_local_prediction = np.where(svr_local_prediction>1, 1, svr_local_prediction)\n",
    "\n",
    "        fold_rmse = np.sqrt(mean_squared_error(valid_fold[target], svr_local_prediction))\n",
    "        \n",
    "        fold_results.append(np.round(fold_rmse, 5))\n",
    "        svr_models_fold[fold_i] = svr_model_local\n",
    "        \n",
    "        print(f\"Current fold: {fold_i}, RMSE {fold_rmse}\")\n",
    "    \n",
    "    return fold_results, svr_models_fold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09d3f9c0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "lin_train_df = train_df.copy()\n",
    "lin_train_df = lin_train_df.replace({-999:0})\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "scaler.fit(lin_train_df[indep])\n",
    "lin_train_df[indep] = scaler.transform(lin_train_df[indep])\n",
    "\n",
    "fold_results, lgb_models_fold = train_svr_model(train_df=lin_train_df)\n",
    "\n",
    "print(\"Fold results:\", fold_results)\n",
    "print(\"Avg.Fold results:\", np.mean(fold_results))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7a9bfb5",
   "metadata": {},
   "source": [
    "# Extra Trees Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4872ecc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ET_model_training(train, valid, n_estimators, params, patience):\n",
    "\n",
    "    np.random.seed(150)\n",
    "    ET = ExtraTreesRegressor(**params)\n",
    "\n",
    "    ET.fit(train[indep], train[target])\n",
    "    ET_prediction = ET.predict(valid[indep])\n",
    "\n",
    "    err = np.sqrt(mean_squared_error(valid[target], ET_prediction))\n",
    "#     print(f\"{1}: {err}\")\n",
    "\n",
    "    best_err = 100000\n",
    "    counter = 0\n",
    "    for i in range(2, n_estimators):\n",
    "        np.random.seed(150)\n",
    "        ET.n_estimators+=1\n",
    "\n",
    "        ET.fit(train[indep], train[target])\n",
    "        ET_prediction = ET.predict(valid[indep])\n",
    "\n",
    "        err = np.sqrt(mean_squared_error(valid[target], ET_prediction))\n",
    "\n",
    "        if err < best_err:\n",
    "            best_err = err\n",
    "            counter = 0\n",
    "#             print(f\"{i}: {err}\")\n",
    "\n",
    "        else:\n",
    "            counter+=1        \n",
    "#             print(f\"{i}: {err}, increasing counter to {counter}\")\n",
    "\n",
    "            if counter == patience:\n",
    "#                 print(f\"Stopping the training at {i} with best error: {best_err}\")\n",
    "                break\n",
    "\n",
    "    return best_err, i, ET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d5dae62",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for depth in range(1, 15):\n",
    "    print(f\"Depth: {depth}\")\n",
    "    ET_params = {'n_estimators':1, \n",
    "                 'max_depth':depth, \n",
    "#                  'min_samples_leaf':10,\n",
    "    #              'min_samples_split':10,\n",
    "                 'warm_start':True}\n",
    "    n_rounds = 1000\n",
    "\n",
    "    fold_iterations = []\n",
    "    fold_results = []\n",
    "    ET_models_fold = {}\n",
    "\n",
    "    for fold_i in range(0, train_df.fold.max()+1):\n",
    "\n",
    "        train_fold = train_df[train_df.fold!=fold_i].copy()\n",
    "        valid_fold = train_df[train_df.fold==fold_i].copy()\n",
    "\n",
    "        fold_err, fold_iter, fold_model_ET = ET_model_training(train=train_fold, \n",
    "                                                               valid=valid_fold, \n",
    "                                                               n_estimators=n_rounds, \n",
    "                                                               params = ET_params,\n",
    "                                                               patience=5)\n",
    "        print(f\"Current fold: {fold_i}, iteration {fold_iter}, RMSE {fold_err}\")\n",
    "\n",
    "        fold_results.append(np.round(fold_err, 5))\n",
    "        fold_iterations.append(fold_iter)\n",
    "        ET_models_fold[fold_i] = fold_model_ET\n",
    "\n",
    "    avg_iteration = int(np.mean(fold_iterations))\n",
    "    print(\"Fold iterations:\", fold_iterations)\n",
    "    print(\"Average iteration:\", avg_iteration)\n",
    "    print(\"Fold results:\", fold_results)\n",
    "    print(\"Avg.Fold results:\", np.mean(fold_results))\n",
    "    print(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a4ddc4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "ET_imp = pd.DataFrame({'indep':indep,\n",
    "                       'imp':ET_models_fold[3].feature_importances_}).sort_values(['imp'], ascending=False).reset_index(drop=True)\n",
    "ET_imp"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77405a03",
   "metadata": {},
   "source": [
    "# Random Forest Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5fbc8a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def RF_model_training(train, valid, n_estimators, params, patience):\n",
    "\n",
    "    np.random.seed(150)\n",
    "    RF = RandomForestRegressor(**params)\n",
    "\n",
    "    RF.fit(train[indep], train[target])\n",
    "    RF_prediction = RF.predict(valid[indep])\n",
    "\n",
    "    err = np.sqrt(mean_squared_error(valid[target], RF_prediction))\n",
    "#     print(f\"{1}: {err}\")\n",
    "\n",
    "    best_err = 100000\n",
    "    counter = 0\n",
    "    for i in range(2, n_estimators):\n",
    "        np.random.seed(150)\n",
    "        RF.n_estimators+=1\n",
    "\n",
    "        RF.fit(train[indep], train[target])\n",
    "        RF_prediction = RF.predict(valid[indep])\n",
    "\n",
    "        err = np.sqrt(mean_squared_error(valid[target], RF_prediction))\n",
    "\n",
    "        if err < best_err:\n",
    "            best_err = err\n",
    "            counter = 0\n",
    "#             print(f\"{i}: {err}\")\n",
    "\n",
    "        else:\n",
    "            counter+=1        \n",
    "#             print(f\"{i}: {err}, increasing counter to {counter}\")\n",
    "\n",
    "            if counter == patience:\n",
    "#                 print(f\"Stopping the training at {i} with best error: {best_err}\")\n",
    "                break\n",
    "\n",
    "    return best_err, i, RF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dcdc903",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for depth in range(3, 15):\n",
    "    print(f\"Depth: {depth}\")\n",
    "\n",
    "    RF_params = {'n_estimators':1,              \n",
    "                 'max_depth':depth, \n",
    "#                  'min_samples_leaf':10,\n",
    "#                  'min_samples_split':10,\n",
    "                 'warm_start':True}\n",
    "    n_rounds = 1000\n",
    "\n",
    "    fold_iterations = []\n",
    "    fold_results = []\n",
    "    RF_models_fold = {}\n",
    "\n",
    "    for fold_i in range(0, train_df.fold.max()+1):\n",
    "\n",
    "        train_fold = train_df[train_df.fold!=fold_i].copy()\n",
    "        valid_fold = train_df[train_df.fold==fold_i].copy()\n",
    "\n",
    "        fold_err, fold_iter, fold_model_RF = RF_model_training(train=train_fold, \n",
    "                                                               valid=valid_fold, \n",
    "                                                               n_estimators=n_rounds, \n",
    "                                                               params = RF_params,\n",
    "                                                               patience=5)\n",
    "        print(f\"Current fold: {fold_i}, iteration {fold_iter}, RMSE {fold_err}\")\n",
    "\n",
    "        fold_results.append(np.round(fold_err, 5))\n",
    "        fold_iterations.append(fold_iter)\n",
    "        RF_models_fold[fold_i] = fold_model_RF\n",
    "\n",
    "    avg_iteration = int(np.mean(fold_iterations))\n",
    "    print(\"Fold iterations:\", fold_iterations)\n",
    "    print(\"Average iteration:\", avg_iteration)\n",
    "    print(\"Fold results:\", fold_results)\n",
    "    print(\"Avg.Fold results:\", np.mean(fold_results))\n",
    "    print(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99445ec2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "RF_imp = pd.DataFrame({'indep':indep,\n",
    "                       'imp':RF_models_fold[3].feature_importances_}).sort_values(['imp'], ascending=False).reset_index(drop=True)\n",
    "RF_imp"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d547f677",
   "metadata": {},
   "source": [
    "# GBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "751c95f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def GBM_model_training(train, valid, n_estimators, params, patience):\n",
    "\n",
    "    np.random.seed(150)\n",
    "    GBM = GradientBoostingRegressor(**params)\n",
    "\n",
    "    GBM.fit(train[indep], train[target])\n",
    "    GBM_prediction = GBM.predict(valid[indep])\n",
    "\n",
    "    err = np.sqrt(mean_squared_error(valid[target], GBM_prediction))\n",
    "#     print(f\"{1}: {err}\")\n",
    "\n",
    "    best_err = 100000\n",
    "    counter = 0\n",
    "    for i in range(2, n_estimators):\n",
    "        np.random.seed(150)\n",
    "        GBM.n_estimators+=1\n",
    "\n",
    "        GBM.fit(train[indep], train[target])\n",
    "        GBM_prediction = GBM.predict(valid[indep])\n",
    "\n",
    "        err = np.sqrt(mean_squared_error(valid[target], GBM_prediction))\n",
    "\n",
    "        if err < best_err:\n",
    "            best_err = err\n",
    "            counter = 0\n",
    "#             print(f\"{i}: {err}\")\n",
    "\n",
    "        else:\n",
    "            counter+=1        \n",
    "#             print(f\"{i}: {err}, increasing counter to {counter}\")\n",
    "\n",
    "            if counter == patience:\n",
    "#                 print(f\"Stopping the training at {i} with best error: {best_err}\")\n",
    "                break\n",
    "\n",
    "    return best_err, i, GBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62eac572",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for depth in range(1, 10):   \n",
    "    print(f\"\\nDepth: {depth}\")\n",
    "    GBM_params = {'n_estimators':1, \n",
    "                 'max_depth':depth, \n",
    "                 'min_samples_leaf':10,\n",
    "                  'learning_rate':0.05,\n",
    "    #              'min_samples_split':10,\n",
    "                 'warm_start':True}\n",
    "    n_rounds = 1000\n",
    "\n",
    "    fold_iterations = []\n",
    "    fold_results = []\n",
    "    GBM_models_fold = {}\n",
    "\n",
    "    for fold_i in range(0, train_df.fold.max()+1):\n",
    "\n",
    "        train_fold = train_df[train_df.fold!=fold_i].copy()\n",
    "        valid_fold = train_df[train_df.fold==fold_i].copy()\n",
    "\n",
    "        fold_err, fold_iter, fold_model_GBM = GBM_model_training(train=train_fold, \n",
    "                                                                 valid=valid_fold, \n",
    "                                                                 n_estimators=n_rounds, \n",
    "                                                                 params = GBM_params,\n",
    "                                                                 patience=5)\n",
    "        print(f\"Current fold: {fold_i}, iteration {fold_iter}, RMSE {fold_err}\")\n",
    "\n",
    "        fold_results.append(np.round(fold_err, 5))\n",
    "        fold_iterations.append(fold_iter)\n",
    "        GBM_models_fold[fold_i] = fold_model_GBM\n",
    "\n",
    "    avg_iteration = int(np.mean(fold_iterations))\n",
    "    print(\"Fold iterations:\", fold_iterations)\n",
    "    print(\"Average iteration:\", avg_iteration)\n",
    "    print(\"Fold results:\", fold_results)\n",
    "    print(\"Avg.Fold results:\", np.mean(fold_results))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b634fd0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "GBM_imp = pd.DataFrame({'indep':indep,\n",
    "                        'imp':GBM_models_fold[3].feature_importances_}).sort_values(['imp'], ascending=False).reset_index(drop=True)\n",
    "GBM_imp"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
